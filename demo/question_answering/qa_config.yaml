# This is the configuration file for the question answering agent. It follows the same syntax as the YAML used for Hydra.
# You can read more about Hydra configuration here: https://hydra.cc/docs/intro/
# The most basic config is the qa_agent. the _target_ key is used to specify the class that will be used to create the agent instance.
# For attributes that can be used for the agent, you can refer the API documentation.

shared_memory:
  _target_: sherpa_ai.memory.shared_memory.SharedMemory  # The absolute path to the share memory class in the library
  objective: Answer the question  # Objective for the agent, since this is a question answering agent, the objective is to answer questions

llm:  # Configuration for the llm, here we are using the OpenAI GPT-3.5-turbo model
  _target_: langchain.chat_models.ChatOpenAI
  model_name: gpt-3.5-turbo
  temperature: 0

agent_config: # For the demo, default configuration is used. You can change the configuration as per your requirement
  _target_: sherpa_ai.config.task_config.AgentConfig

citation_validation:  # The tool used to validate and add citation to the answer
  _target_: sherpa_ai.output_parsers.citation_validation.CitationValidation
  sequence_threshold: 0.5
  jaccard_threshold: 0.5
  token_overlap: 0.5

google_search:  
  _target_: sherpa_ai.actions.GoogleSearch
  role_description: Act as a question answering agent
  task: Question answering
  llm: ${llm}
  include_metadata: true
  config: ${agent_config}

qa_agent:
  _target_: sherpa_ai.agents.qa_agent.QAAgent
  llm: ${llm}
  shared_memory: ${shared_memory}
  name: QA Sherpa
  description: You are a research for natural language processing question for answers to questions. Do not answering any question not related to NLP
  agent_config: ${agent_config}
  num_runs: 1
  validation_steps: 1
  actions:
    - ${google_search}
  validations:
    - ${citation_validation}
