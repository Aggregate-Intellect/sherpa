
==========================================================
Use of Smaller Models as Plugins for Large Language Models 
==========================================================
*Yujing Yang* 

Summary 
-------
The presentation discusses the limitations of large-scale language models and introduces the concept of SuperIn-Context Learning, which utilizes smaller models as plugins to provide task-specific knowledge and predictions. The large language model determines whether to trust the predictions of the smaller models, improving overall performance and providing explanations for predictions. 

Topics: 
-------
	Limitations of large-scale language models 
		* Limited accessibility 
		* Challenges of fine-tuning with large-scale supervised data 
	SuperIn-Context Learning 
		* Utilizes smaller models as plugins 
		* Improves overall performance 
		* Provides explanations for predictions 
	Questions and limitations 
		* Examples were randomly selected 
		* Method is more suitable for tasks with smaller context sizes 
		* Limitations include limited space for showing results and random selection of examples 

