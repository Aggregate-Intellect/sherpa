Generative AI: Ethics, Accessibility, Legal Risk Mitigation
===========================================================

Generative AI has made impressive advances in creating music, art, and
even virtual worlds that were once thought to be exclusively the domain
of human creators. However, with such power comes great responsibility,
and we must be mindful of the ethical implications of our creations. In
this session, we will explore the intersection of generative AI, ethics,
and accessibility. We will examine ethical considerations related to
bias, transparency, and ownership, as well as the challenges of making
generative AI accessible to individuals with disabilities and those from
underrepresented communities.

`SLIDES <#>`__ \| `RECORDING <https://youtu.be/TEixBW1Bnow>`__

**TWITTER THREAD SUMMARY OF THE TALK:**

-  Use of generative AI to improve accessibility and the lives of people
   with disabilities

   -  1/20: When developing generative AI, ethical considerations should
      be at the forefront of our minds. Those of us who are building AI
      systems, and helping others use AI should educate everyone we
      interact with to build more responsibly. #AIethics #generativeAI
      #inclusiveAI
   -  2/20: For example, voice technology combined with generative
      capabilities can improve the lives of people with disabilities.
      Noelle has seen firsthand how these technologies helped her family
      members, and how much more needs to be done still.
   -  3/20: Generative AI has the potential to make conversational
      agents more efficient by eliminating the need for explicit mapping
      of intent and therefore better flexibility to various levels of
      need and speech / communication patterns.
   -  4/20: It is important for AI models to be flexible to accommodate
      new use cases and user personas over time. By incorporating
      flexible and inclusive design principles, AI developers can ensure
      that their technologies are accessible and beneficial to everyone.
   -  5/20: Inclusive engineering is crucial for building good AI
      solutions. It involves team building and data collection with
      diverse perspectives in mind. One of the best ways to achieve this
      is hiring diverse teams with different backgrounds, opinions,
      needs, and demographics.

-  Managing and moderating LLMs to reduce bias, and increase fairness

   -  6/20: Deliberate choices that companies make can reduce the impact
      of bias, and mitigate risks. Mitigating potential issues with LLMs
      requires a comprehensive approach, including diverse datasets,
      fine-tuning foundation models, utilizing hardware resources,
      managing content, and continuous monitoring.
   -  7/20: LLMs are trained on data sets generated by humans, and the
      awareness of potential sources of bias and inaccuracies in that
      data is crucial. Diverse datasets are necessary when training LLMs
      to reduce the impact of those imperfections.
   -  8/20: LLMs make assumptions based on training data. This can
      result in incorrect conclusions. Noelle mentioned that a falsely
      attributed scholarly article was taken as true by an LLM because
      it was making assumptions based on the training data.
   -  9/20: There is a need for inclusive data collection to ensure that
      AI solutions represent end users. Inclusive data collection along
      with keeping track of lineage and context can help mitigate biases
      that may be present in training data.
   -  10/20: LLMs can amplify bias over time, but there are ways to
      mitigate its impact. Having a human-in-the-loop process to
      monitor, manage and control the LLMs is crucial.
      #AmplificationOfBias #HumanInLoop
   -  11/20: LLMs can speed up the process of generating content, but if
      not managed at scale, it can slow down the process by generating
      inappropriate or poor-quality content. Moderation and management
      of the content generated by LLMs are crucial. #ContentGeneration
      #Moderation
   -  12/20: Specific performance metrics for LLMs are essential to
      understand what is a good model and what is not. Continuous
      monitoring by a human team is necessary to ensure that the model
      is working correctly. #PerformanceMetrics #ContinuousMonitoring

-  Versatility and scalability of potential LLM use cases

   -  13/20: LLMs are built on foundation models that can be fine-tuned
      to fit specific business needs. This allows businesses to create
      LLMs tailored to their specific needs and goals, making them
      increasingly popular with companies willing to invest in them.
   -  14/20: The demand for LLMs is growing rapidly, and ML developers
      need to be able to build and deploy them quickly to meet the
      demand. This puts a premium on rapid development and deployment
      processes.
   -  15/20: LLMs can do more than just conversation. They can generate
      natural language requests and responses from various sources,
      including customer signals, website data, and ticketing systems.
      They can even be used to automatically formulate human questions
      and generate Power BI dashboards.
   -  16/20: Next generations of LLMs might be multi-modal which means
      that they can combine different types of input, such as images and
      text, to generate output. This makes them valuable in a variety of
      contexts and use cases.
   -  17/20: LLMs require significant hardware resources to operate, and
      only a few labs in the world can support the required hardware. A
      balance has to be made between building internally, using
      offerings from mainstream vendors, and ones from emergent
      providers.

-  Challenges and Risks of LLMs

   -  18/20: Organizations have a responsibility to guard against
      potential legal issues when using LLMs. Noelle emphasized the
      responsibility of organizations to think through potential legal
      issues and approach projects with an awareness of the risks
      involved.
   -  19/20: Evaluating risks and mitigating them in the solution is
      important. There are use cases for LLMs that are relatively easy
      to approach and mitigate risks, such as customer call centers and
      customer service ticketing. However, more rigor and discipline are
      required for projects using codex, which were trained on Github
      repos.
   -  20/20: Indemnification is important when using LLMs to protect
      against ownership challenges that may arise in the future.
      Enterprise level solutions provide more indemnification than
      research models like Dalle, especially if the model is not custom
      trained on your own art.

**Noelle Russell (Global AI Solutions Lead @ Accenture)**

`Noelle Silver Russell <https://www.linkedin.com/in/noelleai/>`__ is a
multi-award-winning technologist and entrepreneur who specializes in
advising companies on emerging technology, generative AI and LLMs. She
is the Global AI Solutions Lead as well as the Global Industry Lead for
Generative AI at Accenture. She has led teams at NPR, Microsoft, IBM,
and Amazon Alexa, and is a consistent champion for AI literacy and the
ethical use of AI based on her work building some of the largest AI
models in the world. She is the founder of AI Leadership Institute and
she was recently awarded the Microsoft Most Valuable Professional award
for Artificial Intelligence as well as VentureBeatâ€™s Women in AI
Responsibility and Ethics award.

.. image:: https://github.com/Aggregate-Intellect/practical-llms/blob/main/docs/img/noelles.jpeg
  :width: 600
  :alt: Noelle Silver Russell Headshot