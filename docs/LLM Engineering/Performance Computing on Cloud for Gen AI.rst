
=========================================
Performance Computing on Cloud for Gen AI
=========================================
*Farshad Farah* 

Summary 
-------
Farshad Farah provides an overview of high-performance computing for AI/ML in the cloud, with a focus on using Genova. He discusses foundational model providers, fine-tuning models, and inference. He also talks about the challenges faced by foundational model providers and the different approaches to training models on AWS. Farshad shares tips for building large models and discusses the selection of the right model for different use cases. He also addresses data privacy concerns and the availability of AWS solutions. The presentation includes a Q&A session with the audience. 

Topics: 
-------
	Foundational model providers 
		* Foundational model providers offer large-scale models for AI applications 
		* Challenges and pain points faced by foundational model providers 
		* Availability and type of GPUs for training models 
		* Cluster-level thinking for training models 
		* Distributed training and powerful GPUs used by foundational model providers 
	Fine-tuning models 
		* Cloud providers and companies are working to make the fine-tuning process frictionless 
		* Addressing data security concerns in fine-tuning 
		* Access to high-quality models for fine-tuning purposes 
	Inference 
		* Fortune 500 companies seeking guidance on building AI systems using large language models 
		* New models like Falcon 40B enabling exciting possibilities 
		* Specific requirements and requests from Fortune 500 companies regarding inference models 
	Challenges faced by foundational model providers 
		* Availability and type of GPUs for training models 
		* Time and cost considerations for training models 
		* Cluster-level thinking for training models 
		* Powerful GPUs and fast networking crucial for low latency and high bandwidth 
		* Storage options and orchestration layer for managing the cluster effectively 
	Selection of the right model for different use cases 
		* Exploring open source models and their performance improvements 
		* Consideration of performance requirements and long-term commitment 
		* Anthropics Cloud model for the best level of reasoning 
		* AI 21 for multilingual use cases 
		* Stability for visual models 
		* Potential for domain foundational models in specific industries 
	Data privacy concerns 
		* AWS solutions for providing access to foundation models while ensuring data privacy 
		* Amazon Bedrock and Amazon SageMaker Jumpstart for control and security 
		* Hosting models on AWS infrastructure for data privacy 
	Q&A session 
		* Discussion on Sagemaker endpoints and data privacy 
		* Differences between prosumer cards and H100 for distributed training 
		* Challenges of fitting models on one GPU during inference 
		* Exploration of models for coding and comparisons between different models 
		* Selection process for models supported in Bedrock 
		* Availability of Bedrock and its value proposition for data privacy 
		* AWS solutions for domain foundational models 

