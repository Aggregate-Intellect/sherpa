Incorporating Large Language Models into Enterprise Analytics: Navigating the Landscape of In-Context Learning and Agents
=========================================================================================================================

Large Language Models (LLMs) have dramatically changed our expectations
for AI. While a few innovators are building proof-of-concept projects
using APIs, most enterprise analytic teams still need to figure out how
to incorporate LLMs into their analytical toolbox. Rajiv shows the
necessity of understanding the growth of “in-context learning” and
agents. With these insights, he explains how LLMs will shape enterprise
analytics. Along the way, he covers many practical factors, such as the
different providers of LLMs, resource costs, and ethical issues.

`SLIDES <slides/Enterprise_LLMs_Shah.pdf>`__
\| `RECORDING <https://youtu.be/GO6l7dbZIqY>`__

**TWITTER THREAD SUMMARY OF THE TALK:**

-  Advantages and Use Cases of Large Language Models

   -  1/14: NLP use cases in the enterprise primarily focus on text
      classification, summarization, question answering, and embeddings.
      Large language models like GPT-3 and ChatGPT can transform how
      enterprises approach these tasks.
   -  2/14: LLMs offer advantages over traditional NLP models, such as
      better performance in classification and language generation for
      use cases like financial sentiment analysis and customer service
      bots.
   -  3/14: To leverage LLMs in enterprise workflows, companies can
      start by exploring pre-trained models, fine-tuning them on their
      data. However, LLMs are general-purpose models and adding
      domain-specific information might be challenging. Using dedicated
      models for certain tasks, combined with LLMs can be more efficient
      and cost-effective.
   -  4/14: LLMs can connect previously siloed domains in an enterprise,
      allowing for more efficient and natural language searches across
      multiple domains. This makes it easier to access relevant
      information and insights from different parts of the organization.
   -  5/14: The UI is just as important as the model in solving business
      problems. Therefore, it’s essential to focus on UI/UX design in
      addition to developing models. While models can add new
      capabilities, the user interface plays a critical role in
      presenting them in a valuable way.

-  Interfacing LLMs and other Enterprise Systems

   -  6/14: LLMs can be decision-makers, but it’s crucial to set them up
      for success by combining them with other tools. For instance, for
      a math question LLM could be set up to call a calculator and then
      show the result to prevent it from giving the wrong answer with
      confidence.
   -  7/14: Large Language Models can enhance information retrieval by
      combining classic data / knowledge bases with LLMs to provide more
      accurate and human-readable responses to queries. For example,
      LLMs were used to retrieve information on how to install
      Transformers from Huggingface documentation with citation to
      resource.

-  Choosing and Keeping Up with LLMs

   -  8/14: Choosing the right LLM depends on the specific use case, and
      there are various options available with different licensing
      requirements and costs.
   -  9/14: When choosing an LLM, consider factors like availability,
      cost, and accuracy for the specific task at hand. Open source
      models like Hugging Face can provide a wide variety of models and
      tools leveraging the collective knowledge of the community.
   -  10/14: The field of LLMs is evolving rapidly. Staying up to date
      on the latest developments and trends is crucial to make the most
      of this technology. Keep learning to keep improving!
   -  11/14: For those looking to learn AI, OpenAI Sandbox and Hugging
      Face Spaces are excellent starting points. OpenAI Sandbox provides
      templates and examples for learning AI, while Hugging Face is a
      useful resource for natural language processing. LangChain and
      LlamaIndex are also good examples to get started.

-  Democratization and Ethical Considerations in AI

   -  12/14: The democratization of AI is crucial for its widespread
      adoption. Co-pilots and natural language interfaces are enabling
      more people to experiment with AI, even those without a technical
      background. Lowering the barriers to entry for AI can have a
      significant impact on the democratization of AI.
   -  13/14: Ethical considerations are essential in the development and
      deployment of AI. It’s crucial to include diverse voices in the
      design and decision-making processes, educate users on the
      potential dangers of generative AI, and consider the ethical
      implications of AI.
   -  14/14: Bias is a significant challenge in AI. Historic data used
      for training models can perpetuate biases and historical
      injustices. Therefore, it’s crucial to be aware of these biases
      and work towards minimizing their impact.

*Resources*

-  `Talk
   Slides <https://github.com/Aggregate-Intellect/sherpa/blob/main/Enterprise_LLMs_Shah.pdf>`__
-  `Sentiment Spin: Attacking Financial Sentiment with
   GPT-3 <https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4337182>`__
-  `Is ChatGPT a General-Purpose Natural Language Processing Task
   Solver? <https://arxiv.org/abs/2302.06476>`__
-  `Language Models are Few-Shot
   Learners <https://arxiv.org/abs/2005.14165>`__
-  `Transformers learn in-context by gradient
   descent <https://arxiv.org/abs/2212.07677>`__
-  `News Summarization and Evaluation in the Era of
   GPT-3 <https://arxiv.org/abs/2209.12356>`__
-  `Benchmarking Large Language Models for News
   Summarization <https://arxiv.org/abs/2301.13848>`__
-  `BIG-Bench - Beyond the Imitation Game
   Benchmark <https://github.com/google/BIG-bench/>`__
-  `Challenging BIG-Bench Tasks and Whether Chain-of-Thought Can Solve
   Them <https://arxiv.org/abs/2210.09261>`__
-  `ChatGPT for Robotics: Design Principles and Model
   Abilities <https://www.microsoft.com/en-us/research/group/autonomous-systems-group-robotics/articles/chatgpt-for-robotics/>`__
-  `Replicate MRKL chain uding
   LangChain <https://langchain.readthedocs.io/en/latest/modules/agents/implementations/mrkl.html>`__
-  `Experimental Evidence on the Productivity Effects of Generative
   Artificial
   Intelligence <https://economics.mit.edu/sites/default/files/inline-files/Noy_Zhang_1.pdf>`__
-  `The CEO’s Guide to the Generative AI
   Revolution <https://www.bcg.com/publications/2023/ceo-guide-to-ai-revolution>`__
-  `A New Era of Creativity: Expert-in-the-loop Generative
   AI <https://multithreaded.stitchfix.com/blog/2023/03/06/expert-in-the-loop-generative-ai-at-stitch-fix/>`__

----

**Rajiv Shah (MLE @ Huggingface)**

`Rajiv <https://www.linkedin.com/in/rajistics/>`__ is a machine learning
engineer at Hugging Face, whose primary focus is on enabling enterprise
teams to succeed with AI. He is a widely recognized speaker on
enterprise AI and was part of data science teams at Snorkel AI,
Caterpillar, and State Farm.

.. image:: ../_imgs/rajivsh.jpeg
  :width: 400
  :alt: Rajiv Shah Headshot